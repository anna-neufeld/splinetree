<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Forest Building with splinetree • splinetree</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha256-916EbMg70RQy9LHiGkXzG8hSg9EdNy97GazNG/aiY1w=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script><!-- sticky kit --><script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Forest Building with splinetree">
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">splinetree</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.2.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/Forest-intro.html">Forest Building with splinetree</a>
    </li>
    <li>
      <a href="../articles/Long-Intro.html">Introduction to splinetree</a>
    </li>
    <li>
      <a href="../articles/Tree-Intro.html">Tree Building with splinetree</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/anna-neufeld/splinetree">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>Forest Building with splinetree</h1>
                        <h4 class="author">Brianna Heggeseth and Anna Neufeld</h4>
            
            <h4 class="date">2019-07-15</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/anna-neufeld/splinetree/blob/master/vignettes/Forest-intro.Rmd"><code>vignettes/Forest-intro.Rmd</code></a></small>
      <div class="hidden name"><code>Forest-intro.Rmd</code></div>

    </div>

    
    
<p>This guide is meant for users who are familiar with regression trees, random forests, and the spline projection method but who are unfamiliar with the specifics of using the <code>splinetree</code> package. The guide walks through examples of building and evaluating a spline forest. This guide builds off of the vignettes <em>Introduction to splinetree</em> and <em>Tree Building with splinetree</em>. The data used for these examples comes from the National Longitudinal Survey of Youth (NLSY), 1979. In the example, the trajectory of interest is body mass index (BMI) across age, and the split variables are baseline variables related to socioeconomic status and family background.</p>
<div id="building-a-forest" class="section level1">
<h1 class="hasAnchor">
<a href="#building-a-forest" class="anchor"></a>Building a Forest</h1>
<p>For users familiar with building trees in <code>splinetree</code> (see <em>Introduction to Tree Building with splinetree</em>), building a forest is straightforward. The majority of the parameters needed to use the <code><a href="../reference/splineForest.html">splineForest()</a></code> function are identical to those used in the <code><a href="../reference/splineTree.html">splineTree()</a></code> function. The process used to project the longitudinal data onto smoothed trajectories and then make splits is identical. There are just two additional parameters for the <code>splineForest</code> function.</p>
<p>The <code>nTree</code> parameter specifies the number of trees in the forest. The default value is <span class="math inline">\(50\)</span>. Large forests provide additional stability over smaller forests, but on large datasets building a large spline forest may take several minutes. The <code>prob</code> parameter specifies the probability that a variable will be in consideration as a split variable at a given node. To avoid a situation where no variables are considered at a certain node, we recommend that that <code>prob</code> is relatively large when the number of split variables is small. If only 6 split variables are in consideration, then setting <code>prob=1/3</code> leaves around an 8% chance <span class="math inline">\(\left( (2/3)^6 \right)\)</span> that no variable will be selected for a split at the root node. Increasing <code>prob</code> to <code>1/2</code> reduces this probability to under 2%. The <code>bootstrap</code> parameter specifies whether the data subsample used for each tree will be a bootstrap sample (drawn with replacement, size equal to original dataset) or a random sample of 63.2% of the original dataset drawn without replacement. The choice of 63.2% was made because this is how much of the data will be included in a bootstrap sample, on average. Following the work of <span class="citation">Strobl et al. (2007)</span>, who show that sampling without replacement is preferable to the traditional random forest bootstrap sampling, <code>bootstrap=FALSE</code> is the default setting.</p>
<p>We will build a forest of 50 trees using a probability of 0.5. As split variables, we will include indicators for the subject’s race and sex as well as the subject’s number of siblings and the highest grade completed (HGC) by the subject’s mother and father. We will use a spline basis with 1 degree and 1 internal knot; this choice is based on the knowledge that adult BMI trajectories tend to be steeper in early adulthood before flattening out in late adulthood (<span class="citation">Clarke et al. (2008)</span>). We will build both a forest with an intercept for the sake of demonstrating a few functions (such as prediction responses) that are not available for forests without an intercept.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/library">library</a></span>(splinetree)
## Loading required package: rpart
## Loading required package: nlme
## Loading required package: splines
split_formula &lt;-<span class="st"> </span><span class="er">~</span>HISP+WHITE+BLACK+SEX+Num_sibs+HGC_FATHER+HGC_MOTHER
tformula &lt;-<span class="st"> </span>BMI~AGE</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/Random">set.seed</a></span>(<span class="dv">123</span>)
forest &lt;-<span class="st"> </span><span class="kw"><a href="../reference/splineForest.html">splineForest</a></span>(split_formula, tformula, <span class="dt">idvar=</span><span class="st">"ID"</span>, 
                    <span class="dt">data=</span>nlsySample, <span class="dt">degree=</span><span class="dv">1</span>, <span class="dt">df=</span><span class="dv">3</span>,
                    <span class="dt">intercept=</span><span class="ot">TRUE</span>,<span class="dt">ntree=</span><span class="dv">50</span>, <span class="dt">prob=</span><span class="fl">0.5</span>, <span class="dt">cp=</span><span class="fl">0.005</span>)</code></pre></div>
</div>
<div id="working-with-a-spline-forest" class="section level1">
<h1 class="hasAnchor">
<a href="#working-with-a-spline-forest" class="anchor"></a>Working with a spline forest</h1>
<p>This newly built spline forest is a named list with 15 components.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/names">names</a></span>(forest)
##  [1] "Trees"         "index"         "splits"        "data"         
##  [5] "flat_data"     "formula"       "oob_indices"   "degree"       
##  [9] "intercept"     "df"            "boundaryKnots" "innerKnots"   
## [13] "idvar"         "yvar"          "tvar"</code></pre></div>
<p>A few of these 15 components have unsurprising values. For example, <code>forest$data</code> holds a copy of the original dataset, and <code>forest$formula</code>, <code>forest$idvar</code>, <code>forest$yvar</code>, and <code>forest$tvar</code> each hold pieces of information about the call to the <code><a href="../reference/splineTree.html">splineTree()</a></code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">forest$formula
## ~HISP + WHITE + BLACK + SEX + Num_sibs + HGC_FATHER + HGC_MOTHER
forest$idvar
## [1] "ID"
forest$yvar
## [1] "BMI"
forest$tvar
## [1] "AGE"</code></pre></div>
<p>Other components allow us reconstruct the spline basis that was used to build the tree. These are useful for converting coefficients into smoothed trajectories without using built-in functions. The attribute <code>forest$flat_data</code> contains the flattened dataset used to build the trees, including the individually projected coefficients for each individual. We can access the individually projected coefficients in <code>forest$flat_data$Ydata</code>. We can use the average of all the individual coefficients as well as the information that is stored about the spline basis in <code>forest$innerKnots</code>, <code>forest$degree</code>, <code>forest$intercept</code>, and <code>forest$boundaryKnots</code> to reconstruct the population average trajectory.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mean_coeffs &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/apply">apply</a></span>(forest$flat_data$Ydata, <span class="dv">2</span>, mean)

times &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/sort">sort</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/unique">unique</a></span>(forest$data[[forest$tvar]]))


basisMatrix &lt;-<span class="st"> </span><span class="kw">bs</span>(times, <span class="dt">degree=</span>forest$degree, <span class="dt">Boundary.knots =</span> forest$boundaryKnots, 
                  <span class="dt">knots =</span> forest$innerKnots)
if (forest$intercept) {
  basisMatrix &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/cbind">cbind</a></span>(<span class="dv">1</span>, basisMatrix)
}
 
preds &lt;-<span class="st"> </span>basisMatrix %*%<span class="st"> </span>mean_coeffs

<span class="kw"><a href="https://www.rdocumentation.org/packages/graphics/topics/plot">plot</a></span>(times, preds, <span class="dt">type=</span><span class="st">'l'</span>, <span class="dt">main=</span><span class="st">"Population Average Trajectory"</span>)</code></pre></div>
<p><img src="Forest-intro_files/figure-html/unnamed-chunk-5-1.png" width="672"></p>
<p>Apart from all of the information that is stored about the function call and the spline basis, the <code>splineforest</code> model contains information about the forest itself. Most important of all is the component <code>forest$Trees</code>, which stores a list of <code>rpart</code> objects. This ensemble of trees is the fucntional part of the forest model. We can view any individual tree using <code><a href="../reference/stPrint.html">stPrint()</a></code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/stPrint.html">stPrint</a></span>(forest$Trees[[<span class="dv">17</span>]])
## n= 632,  
## 
## node), split, n , coefficients 
##       * denotes terminal node
## 
##  1) root, 632,  (21.71538, 4.893005,  7.979274) 
##    2) HGC_MOTHER&lt; 9.5, 154,  (21.68522, 6.356182,  9.042350) 
##      4) HGC_MOTHER&lt; 0.5, 9,  (24.08324, 8.698686, 12.340970)*
##      5) HGC_MOTHER&gt;=0.5, 145,  (21.53638, 6.210785,  8.837609) 
##       10) HGC_FATHER&lt; 0.5, 8,  (24.19461, 9.357496,  9.022228)*
##       11) HGC_FATHER&gt;=0.5, 137,  (21.38115, 6.027035,  8.826828) 
##         22) BLACK&lt; 0.5, 101,  (21.42788, 5.209842,  8.300523) 
##           44) Num_sibs&lt; 4.5, 65,  (22.09055, 5.140403,  8.592675)*
##           45) Num_sibs&gt;=4.5, 36,  (20.23139, 5.335220,  7.773026)*
##         23) BLACK&gt;=0.5, 36,  (21.25006, 8.319715, 10.303410)*
##    3) HGC_MOTHER&gt;=9.5, 478,  (21.72509, 4.421605,  7.636777) 
##      6) SEX&lt; 1.5, 251,  (22.49986, 4.351190,  7.233788)*
##      7) SEX&gt;=1.5, 227,  (20.86841, 4.499464,  8.082373) 
##       14) Num_sibs&lt; 5.5, 198,  (20.73521, 4.487243,  7.807870) 
##         28) BLACK&lt; 0.5, 133,  (20.50786, 3.712275,  6.932147)*
##         29) BLACK&gt;=0.5, 65,  (21.20039, 6.072946,  9.599734)*
##       15) Num_sibs&gt;=5.5, 29,  (21.77788, 4.582906,  9.956567)*</code></pre></div>
<p>Although we can print any tree in the forest using <code><a href="../reference/stPrint.html">stPrint()</a></code>, it is important to note that these trees are not identical to trees returned by <code><a href="../reference/splineTree.html">splineTree()</a></code>. These <code>rpart</code> trees do not store all of the extra information that is stored in a typical <code><a href="../reference/splineTree.html">splineTree()</a></code> model. For example, we can note the difference between a single tree and <code>forest$Trees[[17]]</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sample_tree &lt;-<span class="st"> </span><span class="kw"><a href="../reference/splineTree.html">splineTree</a></span>(split_formula, tformula, <span class="dt">idvar=</span><span class="st">"ID"</span>, 
                          <span class="dt">data=</span>nlsySample, <span class="dt">degree=</span><span class="dv">1</span>,  <span class="dt">df=</span><span class="dv">2</span>, <span class="dt">intercept=</span><span class="ot">TRUE</span>, <span class="dt">cp=</span><span class="fl">0.005</span>)

### Try to evaluate both trees
<span class="kw"><a href="../reference/yR2.html">yR2</a></span>(sample_tree)
## [1] 0.1701266
test &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/try">try</a></span>(<span class="kw"><a href="../reference/yR2.html">yR2</a></span>(forest$Trees[[<span class="dv">17</span>]]), <span class="dt">silent=</span><span class="ot">TRUE</span>)
<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/class">class</a></span>(test)
## [1] "try-error"

### Try to access additional information from both trees
sample_tree$parms$degree
## [1] 1
forest$Trees[[<span class="dv">17</span>]]$parms$degree
## NULL</code></pre></div>
<p>The remaining components of <code>forest</code> include <code>forest$index</code>, <code>forest$oob_indices</code>, and <code>forest$splits</code>. The <code>index</code> component let’s us access the data that was used to build each tree. For example, <code>forest$index[[17]]</code> stores the indices of each row in <code>forest$flat_data</code> that was used to build the 17th tree. On the other hand, <code>forest$oob_indices[[17]]</code> stores a list of indices that correpond to rows in <code>forest$flat_data</code> that were NOT used to build tree 17 (these rows were “out of the bag”, or “oob”). Storing both of these pieces of information may seem redundant, but both are accessed frequently in the forest prediction and evaluation functions. If we want to uncover datapoints that are “in the bag” and “out of the bag” for tree 17, we can use:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">itb17 &lt;-<span class="st"> </span>forest$flat_data[forest$index[[<span class="dv">17</span>]],]
oob17 &lt;-<span class="st"> </span>forest$flat_data[forest$oob_indices[[<span class="dv">17</span>]],]</code></pre></div>
<p>The <code>in the bag</code> dataset is around twice as large as the <code>out of bag</code> dataset since each tree has 63.2% of the data <code>in the bag</code>.</p>
<p>The final component of a forest is accessed in <code>forest$splits</code>. This very long vector stores the string name of every variable selected as a split throughout the entire forest. It might be useful to compare the frequency with which different variables are selected. It is important to note that these frequecies should <span class="math inline">\(not\)</span> be used as a variable importance metric. The barplot below shows that HGC_FATHER, HGC_MOTHER, and Num_Sibs are the most frequently selected varaibles throughout the forest. These three variables are the only numeric variables in the dataset; the rest are binary, meaning that they can never be used consecutively in the same branch of a tree. More appropriate measures of variable importance will be discussed below.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">freqs &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/table">table</a></span>(forest$splits)/<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/sum">sum</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/table">table</a></span>(forest$splits))
<span class="kw"><a href="https://www.rdocumentation.org/packages/graphics/topics/par">par</a></span>(<span class="dt">las =</span> <span class="dv">2</span>)
<span class="kw"><a href="https://www.rdocumentation.org/packages/graphics/topics/barplot">barplot</a></span>(freqs, <span class="dt">cex.names =</span> <span class="fl">0.5</span>)</code></pre></div>
<p><img src="Forest-intro_files/figure-html/unnamed-chunk-9-1.png" width="672"></p>
<p>The bias in splits towards variables with more unique values is exacerbated in forests where each tree is very large; in forests such as these, numeric variables with many unique values will be repeatedly used for successive splits while binary variables are limited to one split per tree branch. It is sometimes useful to check the size of the average tree in the forest and, if necessary, prune each tree in the forest to reduce the average size.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/avSize.html">avSize</a></span>(forest)
## [1] 9.3
<span class="kw"><a href="../reference/avSize.html">avSize</a></span>(<span class="kw"><a href="../reference/pruneForest.html">pruneForest</a></span>(forest, <span class="dt">cp=</span><span class="fl">0.01</span>))
## [1] 4.62</code></pre></div>
</div>
<div id="making-predictions-with-a-forest" class="section level1">
<h1 class="hasAnchor">
<a href="#making-predictions-with-a-forest" class="anchor"></a>Making predictions with a forest</h1>
<p>Making a prediction using a spline forest involves averaging predictions over individual trees in the forest. When making predictions for a datapoint that was not in the training set, the only reasonable option is to use all the trees in the forest to make the prediction. Using this method, either coefficients or response values (assuming <code>forest$intercept==TRUE</code>) can be predicted. In predicting coefficients, no value is required for the “AGE” variable, but in predicting responses ages must be specified.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">newData &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/data.frame">data.frame</a></span>(<span class="st">"WHITE"</span> =<span class="st"> </span><span class="dv">0</span>, <span class="st">"BLACK"</span>=<span class="dv">1</span>, <span class="st">"HISP"</span>=<span class="dv">0</span>, <span class="st">"Num_sibs"</span>=<span class="dv">3</span>, <span class="st">"HGC_MOTHER"</span>=<span class="dv">12</span>, <span class="st">"HGC_FATHER"</span>=<span class="dv">12</span>, <span class="st">"SEX"</span>=<span class="dv">1</span>)
preds &lt;-<span class="st"> </span><span class="kw"><a href="../reference/predictCoeffsForest.html">predictCoeffsForest</a></span>(forest, <span class="dt">testdata =</span> newData)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">AGE &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="dv">16</span>,<span class="dv">18</span>,<span class="dv">20</span>,<span class="dv">22</span>,<span class="dv">25</span>,<span class="dv">30</span>,<span class="dv">37</span>,<span class="dv">39</span>,<span class="dv">50</span>)
newData2 &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/cbind">cbind</a></span>(AGE, newData)
predictions &lt;-<span class="st"> </span><span class="kw"><a href="../reference/predictYForest.html">predictYForest</a></span>(forest, <span class="dt">testdata=</span>newData2)
<span class="kw"><a href="https://www.rdocumentation.org/packages/graphics/topics/plot">plot</a></span>(AGE, predictions, <span class="dt">type=</span><span class="st">'l'</span>)</code></pre></div>
<p><img src="Forest-intro_files/figure-html/unnamed-chunk-12-1.png" width="672"></p>
<p>When predicting coefficients or responses for a datapoint that was in the training set, we have the option to use one of three different methods, specified by the “methods” parameter in <code>predictYForest</code> and <code>predictCoeffsForest</code>. For a given datapoint, we can either average its prediction over all trees in the forest (<code>method = "all"</code>), over only trees in the forest for which this datapoint was not in the random subsample (<code>method="oob"</code>), or over only trees in the forest for which this datapoint was in the random subsample (<code>method="itb"</code>). The <code>oob</code> method is preferred, as it gives a sense of out-of-sample performance and avoids overfitting the training data. We can compare response predictions for the tree methods in terms of how closely they match the actual responses. As expected, the <code>itb</code> predictions match the actual values much more closely.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/cor">cor</a></span>(nlsySample$BMI, <span class="kw"><a href="../reference/predictYForest.html">predictYForest</a></span>(forest, <span class="dt">method=</span><span class="st">"oob"</span>))
## [1] 0.399546
<span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/cor">cor</a></span>(nlsySample$BMI, <span class="kw"><a href="../reference/predictYForest.html">predictYForest</a></span>(forest, <span class="dt">method=</span><span class="st">"all"</span>))
## [1] 0.4570001
<span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/cor">cor</a></span>(nlsySample$BMI, <span class="kw"><a href="../reference/predictYForest.html">predictYForest</a></span>(forest, <span class="dt">method=</span><span class="st">"itb"</span>))
## [1] 0.4868128</code></pre></div>
</div>
<div id="evaluating-a-forest" class="section level1">
<h1 class="hasAnchor">
<a href="#evaluating-a-forest" class="anchor"></a>Evaluating a Forest</h1>
<p>As with a single tree, we can evaluate a forest with respect to how well it predicts actual responses or with respect to how well it predicts individually-smoothed trajectories. In many cases, it makes more sense to look at how well the forest is predicting actual responses; a forest that is excellent at predicting individually projected trajectories may be mostly useless if the individual trajectories do not approximate the actual responses (due to a poorly chosen basis). However, there are also advantages to evaluating a forest with respect to projected trajectories. The projectedion-based metrics can be used whether or not the forest includes an intercept. Furthermore, they do not give the forest credit for the portion of variation that is explained simply by the population average trend of BMI and AGE; they only give the forest credit for explaining additional variation through covariates. Furthermore, when used on a no-intercept forest or when used with the arguement <code>removeIntercept=TRUE</code>, these metrics tell us how well we explain variation in shape of trajectory, regardless of what is happening with level. When our goal is to explain variation in shape, this metric may be more useful than the prediction metric.</p>
<p>Apart from the response vs. projected response choice, we can also measure forest performance using <code>out-of-the-bag</code>, <code>in-the-bag</code>, or all tree predictions. Out of the bag performance metrics are often preferred because they provide a more realistic assesment of how the tree will perform out of sample. Combining these different dimensions of choice, there are 9 different ways that we could evaluate the performance of one single forest with an intercept! We can compare the 9 metrics.</p>
<p>The response-based <span class="math inline">\(R^2\)</span> measure is the most straightforward. Unsuprisingly, performance is worst using <code>oob</code> predictions and best using <code>itb</code> predictions.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/yR2Forest.html">yR2Forest</a></span>(forest, <span class="dt">method=</span><span class="st">"oob"</span>)
## [1] 0.1591171
<span class="kw"><a href="../reference/yR2Forest.html">yR2Forest</a></span>(forest, <span class="dt">method=</span><span class="st">"all"</span>)
## [1] 0.2073862
<span class="kw"><a href="../reference/yR2Forest.html">yR2Forest</a></span>(forest, <span class="dt">method=</span><span class="st">"itb"</span>)
## [1] 0.2325781</code></pre></div>
<p>The projection based <span class="math inline">\(R^2\)</span> metrics follow the same pattern of <code>oob</code> measures performing the worst, but overall performance is much lower because the forest no longer gets credit for explaining variation that could be explained with the population average BMI vs. AGE trajectory.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/projectedR2Forest.html">projectedR2Forest</a></span>(forest, <span class="dt">method=</span><span class="st">"oob"</span>, <span class="dt">removeIntercept =</span> <span class="ot">FALSE</span>)
##           [,1]
## [1,] 0.0428582
<span class="kw"><a href="../reference/projectedR2Forest.html">projectedR2Forest</a></span>(forest, <span class="dt">method=</span><span class="st">"all"</span>, <span class="dt">removeIntercept =</span> <span class="ot">FALSE</span>)
##           [,1]
## [1,] 0.1049721
<span class="kw"><a href="../reference/projectedR2Forest.html">projectedR2Forest</a></span>(forest, <span class="dt">method=</span><span class="st">"itb"</span>, <span class="dt">removeIntercept =</span> <span class="ot">FALSE</span>)
##           [,1]
## [1,] 0.1371232</code></pre></div>
<p>Finally, when we exclude the intercept, the same patterns hold but we see that even less total variation is explained by our model with we do not give the model credit for explaining variation in starting level. These metrics suggest that, moving out of sample, we will only be able to explain aroudn 3% of variation in shape of BMI trajectory.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/projectedR2Forest.html">projectedR2Forest</a></span>(forest, <span class="dt">method=</span><span class="st">"oob"</span>, <span class="dt">removeIntercept =</span> <span class="ot">TRUE</span>)
##            [,1]
## [1,] 0.03176001
<span class="kw"><a href="../reference/projectedR2Forest.html">projectedR2Forest</a></span>(forest, <span class="dt">method=</span><span class="st">"all"</span>, <span class="dt">removeIntercept =</span> <span class="ot">TRUE</span>)
##           [,1]
## [1,] 0.0730511
<span class="kw"><a href="../reference/projectedR2Forest.html">projectedR2Forest</a></span>(forest, <span class="dt">method=</span><span class="st">"itb"</span>, <span class="dt">removeIntercept =</span> <span class="ot">TRUE</span>)
##            [,1]
## [1,] 0.09379064</code></pre></div>
</div>
<div id="variable-importance" class="section level1">
<h1 class="hasAnchor">
<a href="#variable-importance" class="anchor"></a>Variable Importance</h1>
<p>Our primary motivation in building forests of spline trees is to obtain stable measures of variable importance using a permutation importance metric related to that described in <span class="citation">Breiman (2001)</span> and <span class="citation">Liaw and Wiener (2002)</span>.</p>
<p>For every tree in the forest, tree performance is measured on out-of-the-bag datapoints. Then, the values of variable <span class="math inline">\(V\)</span> are randomly permuted, and tree performance is re-measured. The average difference in performance over all trees in forest becomes the variable importance score for variable <span class="math inline">\(V\)</span>. The <code>splinetree</code> package provides scores using the absolute difference in performance, the percent difference in importance, and standardized difference in importance (differences divided by their standard deviation). In most cases, these three metrics will rank the variables in the same way, and so the choice is a matter of preference.</p>
<p>The “tree performance” metric involved in the permuation importance could be response-based or projection-based, and the latter metric (in the case of forests that include an intercept) can be modified to either include or exclude the intercept. The function <code><a href="../reference/varImpY.html">varImpY()</a></code> implements response-based projection where the tree performance metric used is the Mean Squared Prediction Error (MSE), as in <span class="citation">Liaw and Wiener (2002)</span>. Alternatively, the <code><a href="../reference/varImpCoeff.html">varImpCoeff()</a></code> funcion uses projection sum of squares, and has an additional arguement <code>removeIntercept</code> to specify whether or not the intercept should be included in the projection sum or squares. As with performance metrics, the variable importance metrics can be calculated according to <code>oob</code>, <code>all</code>, or <code>itb</code> frameworks. The <code>oob</code> method is recommended, because in measuring variable importance it is important to consider which variables are most likely to be associated with the outcome outside of our training sample.</p>
<p>We can create three different variable importance matrices using our sample forest. We can then compare the response-based importance to the projection-based importances (both including and ignoring the intercept). Each of these importance matrix contains three columns, corresponding to absolute differences in performance, percent differences in performance, and standardized differences in importance. We will use the third column.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Y_imps &lt;-<span class="st"> </span><span class="kw"><a href="../reference/varImpY.html">varImpY</a></span>(forest, <span class="dt">method=</span><span class="st">"oob"</span>)
coeff_imps &lt;-<span class="st"> </span><span class="kw"><a href="../reference/varImpCoeff.html">varImpCoeff</a></span>(forest, <span class="dt">method=</span><span class="st">"oob"</span>, <span class="dt">removeIntercept=</span><span class="ot">FALSE</span>)
shape_imps &lt;-<span class="st"> </span><span class="kw"><a href="../reference/varImpCoeff.html">varImpCoeff</a></span>(forest, <span class="dt">method=</span><span class="st">"oob"</span>, <span class="dt">removeIntercept=</span><span class="ot">TRUE</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/graphics/topics/par">par</a></span>(<span class="dt">mfrow=</span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="dv">1</span>,<span class="dv">3</span>))
<span class="kw"><a href="../reference/plotImp.html">plotImp</a></span>(Y_imps[,<span class="dv">3</span>], <span class="dt">main=</span><span class="st">"Response"</span>)
<span class="kw"><a href="../reference/plotImp.html">plotImp</a></span>(coeff_imps[,<span class="dv">3</span>], <span class="dt">main =</span> <span class="st">"Coeff w/ Intercept"</span>)
<span class="kw"><a href="../reference/plotImp.html">plotImp</a></span>(shape_imps[,<span class="dv">3</span>], <span class="dt">main =</span> <span class="st">"Coeff w/out Intercept"</span>)</code></pre></div>
<p><img src="Forest-intro_files/figure-html/unnamed-chunk-19-1.png" width="672"></p>
<p>The first two panels of the plot look relatively similar. While based on different performance metrics, both take into account variability explained by the forest with respect to level of the outcome and shape of the trajectory. The high level of agreement between the first two panels suggests that the projected trajectories are reasonable approximations of the true response; variables that are important in explaining the projected trajectories are also important in explaining the actual responses. The third panel shows more stark differences, as this metric defines performance only in terms of explaining the shape of the trajectory. Sex is far less important when level is ignored, suggesting that sex impacts the level of an individual’s BMI but has almost no bearing on trajectory of BMI over time.</p>
</div>
<div id="conclusion" class="section level1">
<h1 class="hasAnchor">
<a href="#conclusion" class="anchor"></a>Conclusion</h1>
<p>Spline forests are useful tools for understanding which variables may be associated with heterogeneity in longitudninal trajectories in a population.</p>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h1>
<div id="refs" class="references">
<div id="ref-breiman2001random">
<p>Breiman, Leo. 2001. “Random Forests.” <em>Machine Learning</em> 45 (1). Springer: 5–32.</p>
</div>
<div id="ref-clarke2008social">
<p>Clarke, Philippa, Patrick M O’malley, Lloyd D Johnston, and John E Schulenberg. 2008. “Social Disparities in Bmi Trajectories Across Adulthood by Gender, Race/Ethnicity and Lifetime Socio-Economic Position: 1986–2004.” <em>International Journal of Epidemiology</em> 38 (2). Oxford University Press: 499–509.</p>
</div>
<div id="ref-liaw2002classification">
<p>Liaw, Andy, and Matthew Wiener. 2002. “Classification and Regression by RandomForest.” <em>R News</em> 2 (3): 18–22.</p>
</div>
<div id="ref-strobl2007bias">
<p>Strobl, Carolin, Anne-Laure Boulesteix, Achim Zeileis, and Torsten Hothorn. 2007. “Bias in Random Forest Variable Importance Measures: Illustrations, Sources and a Solution.” <em>BMC Bioinformatics</em> 8 (1). BioMed Central: 25.</p>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#building-a-forest">Building a Forest</a></li>
      <li><a href="#working-with-a-spline-forest">Working with a spline forest</a></li>
      <li><a href="#making-predictions-with-a-forest">Making predictions with a forest</a></li>
      <li><a href="#evaluating-a-forest">Evaluating a Forest</a></li>
      <li><a href="#variable-importance">Variable Importance</a></li>
      <li><a href="#conclusion">Conclusion</a></li>
      <li><a href="#references">References</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Anna Neufeld, Brianna Heggeseth.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.3.0.</p>
</div>
      </footer>
</div>

  

  </body>
</html>
